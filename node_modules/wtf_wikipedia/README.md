<div align="center">
  <div><b>wtf_wikipedia</b></div>
  <img src="https://user-images.githubusercontent.com/399657/68222691-6597f180-ffb9-11e9-8a32-a7f38aa8bded.png"/>
  <div>parse data from wikipedia</div>
  <div><code>npm install wtf_wikipedia</code></div>
  <div align="center">
    <sub>
      by
      <a href="https://github.com/spencermountain">Spencer Kelly</a> and
      <a href="https://github.com/spencermountain/wtf_wikipedia/graphs/contributors">
        many contributors
      </a>
    </sub>
  </div>
  <img height="25px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

<div align="center">
  <div>
    <a href="https://npmjs.org/package/wtf_wikipedia">
    <img src="https://img.shields.io/npm/v/wtf_wikipedia.svg?style=flat-square" />
  </a>
  <a href="https://codecov.io/gh/spencermountain/wtf_wikipedia">
    <img src="https://codecov.io/gh/spencermountain/wtf_wikipedia/branch/master/graph/badge.svg" />
  </a>
  <a href="https://bundlephobia.com/result?p=wtf_wikipedia">
    <img src="https://badge-size.herokuapp.com/spencermountain/wtf_wikipedia/master/builds/wtf_wikipedia-client.min.js" />
  </a>
  </div>
</div>

<!-- spacer -->
<img height="15px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

<div align="left">
  <img height="30px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>
  <img height="30px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>
  it is <a href="https://osr.cs.fau.de/wp-content/uploads/2017/09/wikitext-parser.pdf">very</a>, <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/ParsingWikitext">very</a> hard.  &nbsp;  &nbsp; 
  <span> &nbsp;  &nbsp; we're <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:Times_that_100_Wikipedians_supported_something">not</a> <a href="https://twitter.com/ftrain/status/1036060636587978753">joking</a>.</span>
</div>

<!-- einstein sentence -->
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/43598341-75ca8f94-9652-11e8-9b91-cabae4fb1dce.png"/>
</div>

<div align="center">
<img height="30px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>
</div>

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

```js
const wtf = require('wtf_wikipedia')

wtf.fetch('Toronto Raptors').then(doc => {
  doc.sentences(0).text()
  //'The Toronto Raptors are a Canadian professional basketball team ...'

  let coach = doc.infobox().get('coach')
  coach.text() //'Nick Nurse'
})
```

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

## .text

get clean plaintext:

```js
let str = `[[Greater_Boston|Boston]]'s [[Fenway_Park|baseball field]] has a {{convert|37|ft}} wall. <ref>Field of our Fathers: By Richard Johnson</ref>`
wtf(str).text()
// "Boston's baseball field has a 37ft wall."
```

```js
let doc = await wtf.fetch('Glastonbury', 'en')
doc.text()
// 'Glastonbury is a town and civil parish in Somerset, England, situated at a dry point ...'
```

<div align="right">
  <a href="https://observablehq.com/@spencermountain/wtf-wikipedia-text">.text() docs</a>
</div>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221837-0d142480-ffb8-11e9-9d30-90669f1b897c.png"/>
</div>

## .json

get all the data from a page:

```js
let doc = await wtf.fetch('Whistling')

doc.json()
// { categories: ['Oral communication', 'Vocal skills'], sections: [{ title: 'Techniques' }], ...}
```

the default json output is [really verbose](https://observablehq.com/@spencermountain/wtf-wikipedia-json), but you can cherry-pick things like this:

```js
// get just the links:
doc.links().map(link => link.json())
//[{ page: 'Theatrical superstitions', text: 'supersitions' }]

// just the images:
doc.images(0).json()
// { file: 'Image:Duveneck Whistling Boy.jpg', url: 'https://commons.wiki...' }

// json for a particular section:
doc
  .sections('see also')
  .links(0)
  .json()
// { page: 'Slide Whistle' }
```

<div align="right">
  <a href="https://observablehq.com/@spencermountain/wtf-wikipedia-json">.json() docs</a>
</div>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

run it on the client-side:

```html
<script src="https://unpkg.com/wtf_wikipedia"></script>
<script>
  // follow a redirect:
  wtf.fetch('On a Friday', function(err, doc) {
    let members = doc.infobox().get('current members')
    members.links().map(l => l.page())
    //['Thom Yorke', 'Jonny Greenwood', 'Colin Greenwood'...]
  })
</script>
```

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221837-0d142480-ffb8-11e9-9d30-90669f1b897c.png"/>
</div>

### full wikipedia dumps

With this library, in conjunction with [dumpster-dive](https://github.com/spencermountain/dumpster-dive), you can parse the whole english wikipedia in an aftertoon.

```bash
npm install -g dumpster-dive
```

<img height="280px" src="https://user-images.githubusercontent.com/399657/40262198-a268b95a-5ad3-11e8-86ef-29c2347eec81.gif"/>

<div align="right">
  <a href="https://github.com/spencermountain/dumpster-dive/">dumpster docs</a>
</div>

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

## Tutorials

- [Gentle Introduction](https://observablehq.com/@spencermountain/wtf_wikipedia-tutorial?collection=@spencermountain/wtf_wikipedia) - Getting NBA Team data
- [Parsing tables](https://observablehq.com/@spencermountain/parsing-wikipedia-tables) - getting all Apollo Astronauts as JSON
- [Parsing Timezones](https://observablehq.com/@spencermountain/parsing-timezones-from-wikipedia)
- [MBL season schedules](https://observablehq.com/@spencermountain/wikipedia-baseball-table-parser?collection=@spencermountain/wtf_wikipedia)
- [Fetching a list of pages](https://observablehq.com/@spencermountain/parsing-a-list-of-wikipedia-articles)
- [Parsing COVID outbreak table](https://observablehq.com/@spencermountain/parsing-wikipedias-coronavirus-outbreak-data?collection=@spencermountain/wtf_wikipedia)

### Plugins

|                                |                 |
| ------------------------------ | --------------- |
| [html](./plugins/html)         | output html     |
| [markdown](./plugins/markdown) | output markdown |
| [latex](./plugins/latex)       | output latex    |

|                                |                                        |
| ------------------------------ | -------------------------------------- |
| [i18n](./plugins/i18n)         | improve multilingual template coverage |
| [classify](./plugins/classify) | is the article about a person?         |
| [summary](./plugins/summary)   | small description text                 |

|                                |                                    |
| ------------------------------ | ---------------------------------- |
| [category](./plugins/category) | parse all articles in a category   |
| [image](./plugins/image)       | additional methods for `.images()` |

|                                                       |                               |
| ----------------------------------------------------- | ----------------------------- |
| [wtf-mlb](https://github.com/spencermountain/wtf-mlb) | baseball team & season parser |
| [wtf-nhl](https://github.com/spencermountain/wtf-nhl) | hockey team & season parser   |

<div align="right">
  <a href="https://observablehq.com/@spencermountain/wtf-wikipedia-plugins">plugin docs</a>
</div>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

### Ok first, ðŸ›€

[Wikitext](https://en.wikipedia.org/wiki/Help:Wikitext) is no small thing.

Consider:

- _the partial-implementation of [inline-css](https://en.wikipedia.org/wiki/Help:HTML_in_wikitext),_
- _nested elements do not honour the scope of other elements_
- _the language has no errors_
- _deep recursion of [similar-syntax](https://en.wikipedia.org/wiki/Wikipedia:Database_reports/Templates_transcluded_on_the_most_pages) templates_
- _the [egyptian hieroglyphics syntax](https://en.wikipedia.org/wiki/Help:WikiHiero_syntax)_
- _['Birth_date_and_age'](https://en.wikipedia.org/wiki/Template:Birth_date_and_age) vs ['Birth-date_and_age'](https://en.wikipedia.org/wiki/Template:Birth-date_and_age)_
- _the unexplained [hashing scheme](https://commons.wikimedia.org/wiki/Commons:FAQ#What_are_the_strangely_named_components_in_file_paths.3F) for image paths_
- _the [custom encoding](https://en.wikipedia.org/wiki/Wikipedia:Naming_conventions) of whitespace and punctuation_
- _[right-to-left](https://www.youtube.com/watch?v=xpumLsaAWGw) values in left-to-right templates_
- _[PEG-based](https://pegjs.org/) parsers struggle with wikitext's backtracking/lookarounds_
- _there are [634,755](https://s3-us-west-1.amazonaws.com/spencer-scratch/allTemplates-2018-10-26.tsv) templates in en-wikipedia (as of Nov-2018)_
- _there are a large number of pages that don't render properly on wikipedia, or its apps.._

this library supports many **_recursive shenanigans_**, depreciated and **obscure template** variants, and illicit **wiki-shorthands**.

#### What it does:

- Detects and parses **redirects** and **disambiguation** pages
- Parse **infoboxes** into a formatted key-value object
- Handles recursive templates and links- like [[.. [[...]] ]]
- **_Per-sentence_** plaintext and link resolution
- Parse and format internal links
- creates
  [image thumbnail urls](https://commons.wikimedia.org/wiki/Commons:FAQ#What_are_the_strangely_named_components_in_file_paths.3F)
  from **File:XYZ.png** filenames
- Properly resolve dynamic templates like _{{CURRENTMONTH}}_ and _{{CONVERT ..}}_
- Parse **images**, **headings**, and **categories**
- converts 'DMS-formatted' **_(59Â°12\'7.7"N)_** geo-coordinates to lat/lng
- parse and combine citation and reference metadata
- Eliminate xml, latex, css, and table-sorting cruft

#### What doesn't do:

- external '[transcluded](https://en.wikipedia.org/wiki/Wikipedia:Transclusion)' page data [[1](https://github.com/spencermountain/wtf_wikipedia/issues/223)]
- **AST** output
- smart (or 'pretty') formatting of html in infoboxes or galleries [[1](https://github.com/spencermountain/wtf_wikipedia/issues/173)]
- maintain perfect page order [[1]](https://github.com/spencermountain/wtf_wikipedia/issues/88)
- per-sentence references (by 'section' element instead)
- maintain template or infobox css styling

It is built to be as flexible as possible. In all cases, tries to fail in considerate ways.

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

#### How about html scraping..?

Wikimedia's [official parser](https://www.mediawiki.org/wiki/Parsoid) turns wikitext âž” HTML.

<!-- You can even get html from the api [like this](https://en.wikipedia.org/w/api.php?format=json&origin=*&action=parse&prop=text&page=Whistling). -->

if you prefer this **_screen-scraping_** workflow, you can pluck at parts of a page [like that](https://observablehq.com/@mbostock/working-with-wikipedia-data).

that's cool!

getting structured data this way is still a complex, weird process.
Manually _spelunking_ the html is sometimes just as tricky and error-prone as scanning the wikitext itself.

The contributors to this library have come to that conclusion, [as many others have](https://www.mediawiki.org/wiki/Alternative_parsers).

This library has (_lovingly_) borrowed a lot of code and data from the parsoid project, and is gracious to those contributors.

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

## enough chat.

flip your wikitext into a Doc object

```javascript
import wtf from 'wtf_wikipedia'

let txt = `
==Wood in Popular Culture==
* harry potter's wand
* the simpsons fence
`
wtf(txt)
// Document {text(), json(), lists()...}
```

#### **doc.links()**

```javascript
let str = `Whistling is featured in a number of television shows, such as [[Lassie (1954 TV series)|''Lassie'']], and the title theme for ''[[The X-Files]]''.`
let doc = wtf(str)
doc.links().map(l => l.page())
// [ 'Lassie (1954 TV series)',  'The X-Files' ]
```

#### **doc.text()**

returns nice plain-text of the article

```js
var wiki =
  "[[Greater_Boston|Boston]]'s [[Fenway_Park|baseball field]] has a {{convert|37|ft}} wall.<ref>{{cite web|blah}}</ref>"
var text = wtf(wiki).text()
//"Boston's baseball field has a 37ft wall."
```

#### **doc.sections()**:

a section is a heading _'==Like This=='_

```js
wtf(page)
  .sections(1)
  .children() //traverse nested sections
wtf(page)
  .sections('see also')
  .remove() //delete one
```

#### **doc.sentences()**

```js
s = wtf(page).sentences(4)
s.links()
s.bolds()
s.italics()
s.dates() //structured date templates
```

#### **doc.categories()**

```js
let doc = await wtf.fetch('Whistling')
doc.categories()
//['Oral communication', 'Vocal music', 'Vocal skills']
```

#### **doc.images()**

```js
img = wtf(page).images(0)
img.url() // the full-size wikimedia-hosted url
img.thumbnail() // 300px, by default
img.format() // jpg, png, ..
```

<!-- spacer -->
<img height="15px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

## Fetch

This library can grab, and automatically-parse articles from [any wikimedia api](https://www.mediawiki.org/wiki/API:Main_page).
This includes any language, any wiki-project, and most **3rd-party wikis**.

```js
// 3rd-party wiki
let doc = await wtf.fetch('https://muppet.fandom.com/wiki/Miss_Piggy')

// wikipedia franÃ§ais
doc = await wtf.fetch('Tony Hawk', 'fr')
doc.sentences(0).text() // 'Tony Hawk est un skateboarder professionnel et un acteur ...'

// accept an array, or wikimedia pageIDs
let docs = wtf.fetch(['Whistling', 2983], { follow_redirects: false })

// article from german wikivoyage
wtf.fetch('Toronto', { lang: 'de', wiki: 'wikivoyage' }).then(doc => {
  console.log(doc.sentences(0).text()) // 'Toronto ist die Hauptstadt der Provinz Ontario'
})
```

you may also pass the wikipedia page id as parameter instead of the page title:

```javascript
let doc = await wtf.fetch(64646, 'de')
```

the fetch method follows redirects.

### fetch categories:

**wtf.category(title, [lang], [options | callback])**

retrieves all pages and sub-categories belonging to a given category:

```js
let result = await wtf.category('Category:Politicians_from_Paris')
//{
//  pages: [{title: 'Paul Bacon', pageid: 1266127 }, ...],
//  categories: [ {title: 'Category:Mayors of Paris' } ]
//}
```

to fetch and parse all pages in a category, in an optimized way, see [wtf-plugin-category](./plugins/category)

### fetch random article:

**wtf.random(title, [lang], [options | callback])**

retrieves all pages and sub-categories belonging to a given category:

```js
let result = await wtf.category('Category:Politicians_from_Paris')
//{
//  pages: [{title: 'Paul Bacon', pageid: 1266127 }, ...],
//  categories: [ {title: 'Category:Mayors of Paris' } ]
//}
```

### Good practice:

The wikipedia api is [pretty welcoming](https://www.mediawiki.org/wiki/API:Etiquette#Request_limit) though recommends three things, if you're going to hit it heavily -

- pass a `Api-User-Agent` as something so they can use to easily throttle bad scripts
- bundle multiple pages into one request as an array (say, groups of 5?)
- run it serially, or at least, [slowly](https://www.npmjs.com/package/slow).

```js
wtf
  .fetch(['Royal Cinema', 'Aldous Huxley'], 'en', {
    'Api-User-Agent': 'spencermountain@gmail.com'
  })
  .then(docList => {
    let links = docList.map(doc => doc.links())
    console.log(links)
  })
```

---

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

## API

- **.title()** - get/set the title of the page from the first-sentence
- **.pageID()** - get/set the wikimedia id of the page, if we have it.
- **.url()** - (try to) generate the url for the current article
- **.lang()** - get/set the current language (used for url method)
- **.namespace()** - get/set the wikimedia namespace of the page, if we have it
- **.isRedirect()** - if the page is just a redirect to another page
- **.redirectTo()** - the page this redirects to
- **.isDisambiguation()** - is this a placeholder page to direct you to one-of-many possible pages
- **.categories()** -
- **.sections()** - return a list, or given-index of the Document's sections
- **.paragraphs()** - return a list, or given-index of Paragraphs, in all sections
- **.sentences()** - return a list, or given-index of all sentences in the document
- **.images()** -
- **.links()** - return a list, or given-index of all links, in all parts of the document
- **.lists()** - sections in a page where each line begins with a bullet point
- **.tables()** - return a list, or given-index of all structured tables in the document
- **.templates()** - any type of structured-data elements, typically wrapped in like {{this}}
- **.infoboxes()** - specific type of template, that appear on the top-right of the page
- **.references()** - return a list, or given-index of 'citations' in the document
- **.coordinates()** - geo-locations that appear on the page
- **.text()** - plaintext, human-readable output for the page
- **.json()** - a 'stringifyable' output of the page's main data

### Section

- **.title()** - the name of the section, between ==these tags==
- **.index()** - which number section is this, in the whole document.
- **.indentation()** - how many steps deep into the table of contents it is
- **.sentences()** - return a list, or given-index, of sentences in this section
- **.paragraphs()** - return a list, or given-index, of paragraphs in this section
- **.links()** -
- **.tables()** -
- **.templates()** -
- **.infoboxes()** -
- **.coordinates()** -
- **.lists()** -
- **.interwiki()** - any links to other language wikis
- **.images()** - return a list, or given index, of any images in this section
- **.references()** - return a list, or given index, of 'citations' in this section
- **.remove()** - remove the current section from the document
- **.nextSibling()** - a section following this one, under the current parent: eg. 1920s â†’ 1930s
- **.lastSibling()** - a section before this one, under the current parent: eg. 1930s â†’ 1920s
- **.children()** - any sections more specific than this one: eg. History â†’ [PreHistory, 1920s, 1930s]
- **.parent()** - the section, broader than this one: eg. 1920s â†’ History
- **.text()** -
- **.json()** -

### Paragraph

- **.sentences()** -
- **.references()** -
- **.lists()** -
- **.images()** -
- **.links()** -
- **.interwiki()** -
- **.text()** - generate readable plaintext for this paragraph
- **.json()** - generate some generic data for this paragraph in JSON format

### Sentence

- **.links()** -
- **.bolds()** -
- **.italics()** -
- **.dates()** -
- **.json()** -

### Image

- **.url()** - return url to full size image
- **.thumbnail()** - return url to thumbnail (pass `size` to customize)
- **.links()** - any links from the caption (if present)
- **.format()** - get file format (e.g. `jpg`)
- **.json()** - return some generic metadata for this image
- **.text()** - does nothing

### Infobox

- **.links()** -
- **.keyValue()** - generate simple key:value strings from this infobox
- **.image()** - grab the main image from this infobox
- **.get()** - lookup properties from their key
- **.template()** - which infobox, eg 'Infobox Person'
- **.text()** - generate readable plaintext for this infobox
- **.json()** - generate some generic 'stringifyable' data for this infobox

### List

- **.lines()** - get an array of each member of the list
- **.links()** - get all links mentioned in this list
- **.text()** - generate readable plaintext for this list
- **.json()** - generate some generic easily-parsable data for this list

### Reference

- **.title()** - generate human-facing text for this reference
- **.links()** - get any links mentioned in this reference
- **.text()** - returns nothing
- **.json()** - generate some generic metadata data for this reference

### Table

- **.links()** - get any links mentioned in this table
- **.keyValue()** - generate a simple list of key:value objects for this table
- **.text()** - returns nothing
- **.json()** - generate some useful metadata data for this table

<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

## Configuration

### Adding new methods:

you can add new methods to any class of the library, with `wtf.extend()`

```js
wtf.extend(models => {
  // throw this method in there...
  models.Doc.prototype.isPerson = function() {
    return this.categories().find(cat => cat.match(/people/))
  }
})

await wtf.fetch('Stephen Harper').isPerson() //hmm?
```

### Adding new templates:

does your wiki use a `{{foo}}` template? Add a custom parser for it:

```js
wtf.extend((models, templates) => {
  // create a custom parser function
  templates.foo = (text, data) => {
    data.templates.push({ name: 'foo', cool: true })
    return 'new-text'
  }

  // array-syntax allows easy-labeling of parameters
  templates.foo = ['a', 'b', 'c']

  // number-syntax for returning by param # '{{name|zero|one|two}}'
  templates.baz = 0

  // replace the template with a string '{{asterisk}}' -> '*'
  templates.asterisk = '*'
})
```

<div align="right">
  <a href="https://observablehq.com/@spencermountain/wtf-wikipedia-plugins">plugin docs</a>
</div>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

## Notes:

### 3rd-party wikis

by default, [a public API](https://www.mediawiki.org/wiki/API:Main_page) is provided by a installed mediawiki application.
This means that most wikis have an open api, even if they don't realize it. Some wikis may turn this feature off.

It can usually be found by visiting `http://mywiki.com/api.php`

to fetch pages from a 3rd-party wiki:

```js
wtf.fetch('Kermit', { domain: 'muppet.fandom.com' }).then(doc => {
  console.log(doc.text())
})
```

some wikis will change the path of their API, from `./api.php` to elsewhere. If your api has a different path, you can set it like so:

```js
wtf.fetch('2016-06-04_-_J.Fernandes_@_FIL,_Lisbon', { domain: 'www.mixesdb.com', path: 'db/api.php' }).then(doc => {
  console.log(doc.templates('player'))
})
```

### i18n and multi-language:

wikitext is (amazingly) used across all languages, wikis, and even in right-to-left languages.
This parser actually does an okay job at it too.

Wikipedia I18n langauge information for _Redirects, Infoboxes, Categories, and Images_ are included in the library, with pretty-decent coverage.

To improve coverage of i18n templates, use [wtf-plugin-i18n](./plugins/i18n)

Please make a PR if you see something missing for your language.

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

## Builds:

this library ships seperate client-side and server-side builds, to preserve filesize.

- _[./wtf_wikipedia-client.js](./builds/wtf_wikipedia-client.js)_ - with sourcemap
- _[./wtf_wikipedia-client.mjs](./builds/wtf_wikipedia-client.js)_ - as es-module (or Deno)
- _[./wtf_wikipedia-client.min.js](./builds/wtf_wikipedia-client.js)_ - for production

- _[./wtf_wikipedia.js](./builds/wtf_wikipedia.js)_ - main node build
- _[./wtf_wikipedia.mjs](./builds/wtf_wikipedia.mjs)_ - esmodule node (typescript)

the browser version uses `fetch()` and the server version uses `require('https')`.

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>

## Performance:

It is not the fastest parser, and is very unlikely to beat a [single-pass parser](https://www.mediawiki.org/wiki/Alternative_parsers) in C or Java.

Using [dumpster-dive](https://github.com/spencermountain/dumpster-dive), this library can parse a full english wikipedia in around 4 hours on a macbook.

That's about 100 pages/second, per thread.

<!-- spacer -->
<img height="50px" src="https://user-images.githubusercontent.com/399657/68221862-17ceb980-ffb8-11e9-87d4-7b30b6488f16.png"/>
<div align="center">
  <img height="50px" src="https://user-images.githubusercontent.com/399657/68221824-09809d80-ffb8-11e9-9ef0-6ed3574b0ce8.png"/>
</div>

## See also:

alternative javascript parsers:

- [instaview](https://github.com/cscott/instaview)
- [txtwiki](https://github.com/joaomsa/txtwiki.js)
- [Parsoid](https://www.mediawiki.org/wiki/Parsoid)
- [wiky](https://github.com/Gozala/wiky)

and [many more](https://www.mediawiki.org/wiki/Alternative_parsers)!

MIT
